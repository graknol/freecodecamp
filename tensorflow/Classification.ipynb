{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
                "\r\n",
                "from path import Path\r\n",
                "import pandas as pd\r\n",
                "from IPython.display import clear_output\r\n",
                "import tensorflow as tf"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\r\n",
                "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "train_path = tf.keras.utils.get_file('iris_training.csv', 'https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')\r\n",
                "test_path = tf.keras.utils.get_file('iris_test.csv', 'https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv')\r\n",
                "\r\n",
                "clear_output()\r\n",
                "\r\n",
                "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\r\n",
                "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\r\n",
                "\r\n",
                "print(train.head())\r\n",
                "\r\n",
                "train_y = train.pop('Species')\r\n",
                "test_y = test.pop('Species')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
                        "0          6.4         2.8          5.6         2.2        2\n",
                        "1          5.0         2.3          3.3         1.0        1\n",
                        "2          4.9         2.5          4.5         1.7        2\n",
                        "3          4.9         3.1          1.5         0.1        0\n",
                        "4          5.7         3.8          1.7         0.3        0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "train.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(120, 4)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "def input_fn(features, labels, training=True, batch_size=256):\r\n",
                "    ds = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n",
                "    if training:\r\n",
                "        ds = ds.shuffle(1000).repeat()\r\n",
                "    return ds.batch(batch_size)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "feature_columns = []\r\n",
                "for key in train.keys():\r\n",
                "    feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n",
                "print(feature_columns)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "classifier = tf.estimator.DNNClassifier(\r\n",
                "    feature_columns=feature_columns,\r\n",
                "    # Two hidden layers of 30 and 10 nodes respectively\r\n",
                "    hidden_units=[30, 10],\r\n",
                "    # The model must choose between 3 classes\r\n",
                "    n_classes=3\r\n",
                ")\r\n",
                "clear_output()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "classifier.train(\r\n",
                "    input_fn=lambda: input_fn(train, train_y, training=True),\r\n",
                "    steps=5000)\r\n",
                "clear_output()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\r\n",
                "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "INFO:tensorflow:Calling model_fn.\n",
                        "INFO:tensorflow:Done calling model_fn.\n",
                        "INFO:tensorflow:Starting evaluation at 2021-07-22T09:07:53\n",
                        "INFO:tensorflow:Graph was finalized.\n",
                        "INFO:tensorflow:Restoring parameters from C:\\Users\\SC-23431\\AppData\\Local\\Temp\\tmp_ph1m_i3\\model.ckpt-10000\n",
                        "INFO:tensorflow:Running local_init_op.\n",
                        "INFO:tensorflow:Done running local_init_op.\n",
                        "INFO:tensorflow:Inference Time : 0.30700s\n",
                        "INFO:tensorflow:Finished evaluation at 2021-07-22-09:07:53\n",
                        "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.8666667, average_loss = 0.42855814, global_step = 10000, loss = 0.42855814\n",
                        "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: C:\\Users\\SC-23431\\AppData\\Local\\Temp\\tmp_ph1m_i3\\model.ckpt-10000\n",
                        "\n",
                        "Test set accuracy: 0.867\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "source": [
                "def input_fn(features, batch_size=256):\r\n",
                "    return tf.data.Dataset.from_tensor_slices(features).batch(batch_size)\r\n",
                "\r\n",
                "predict = {}\r\n",
                "\r\n",
                "print('Please type numeric values as prompted')\r\n",
                "for feature in train.keys():\r\n",
                "    valid = False\r\n",
                "    while not valid:\r\n",
                "        val = input(feature + ': ')\r\n",
                "        try:\r\n",
                "            predict[feature] = [float(val)]\r\n",
                "            valid = True\r\n",
                "        except ValueError:\r\n",
                "            pass\r\n",
                "\r\n",
                "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\r\n",
                "for pred_dict in predictions:\r\n",
                "    for class_id in pred_dict['class_ids']:\r\n",
                "        probability = pred_dict['probabilities'][class_id]\r\n",
                "        print('Prediction is: \"{}\" ({:.1f}%)'.format(SPECIES[class_id], 100 * probability))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Please type numeric values as prompted\n",
                        "INFO:tensorflow:Calling model_fn.\n",
                        "INFO:tensorflow:Done calling model_fn.\n",
                        "INFO:tensorflow:Graph was finalized.\n",
                        "INFO:tensorflow:Restoring parameters from C:\\Users\\SC-23431\\AppData\\Local\\Temp\\tmp_ph1m_i3\\model.ckpt-10000\n",
                        "INFO:tensorflow:Running local_init_op.\n",
                        "INFO:tensorflow:Done running local_init_op.\n",
                        "Prediction is: \"Virginica\" (62.7%\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('fcc_tf': conda)"
        },
        "interpreter": {
            "hash": "8a577243463c9fb053d577f44012f92c98057b00b50ce53cdc784040c960c971"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}